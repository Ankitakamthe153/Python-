{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../input/human-activity-recognition-with-smartphones/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(path,'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(path,'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['Activity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".Human Activity Recognition\n",
    "In this notebook, we are trying to predict the Activity of a user. As you can it is a Muliclassification Problem. This notebook is to build a model that can predict whether a person is Laying, Standing , Sitting, Walking, Walking_upstairs, or Walking_downstairs\n",
    "\n",
    "Initially, the information in this dataset is the measurements from the accelerometer, gyroscope, magnetometer, and GPS of the smartphone.\n",
    "Data Information\n",
    "From the website:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions\n",
    "\n",
    "The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.\n",
    "Let's talk about the features (columns)\n",
    "We see, there are 563 individual features(columns).\n",
    "\n",
    "The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ . These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise.\n",
    "Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz.\n",
    "Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ) . Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag)\n",
    "jerk is the rate at which an object's acceleration changes with respect to time\n",
    "\n",
    "Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing\n",
    "fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag.\n",
    "\n",
    "(Note the 'f' to indicate frequency domain signals).\n",
    "\n",
    "These signals were used to estimate variables of the feature vector for each pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's our Plan?\n",
    "\n",
    "\n",
    "### `Outline`\n",
    "\n",
    "- <b>1. Read Dataset </b>\n",
    "\n",
    "\n",
    "- <b>2. Datset Cleaning </b>\n",
    "    - 2.1 Outliers\n",
    "    - 2.2 Filling null values\n",
    "    - 2.3 Check for data imbalance\n",
    "    - 2.4 Correcting some feature names\n",
    "\n",
    "\n",
    "   \n",
    "- <b>3. Exploratory Data Analysis </b>\n",
    "\n",
    "\n",
    "- <b>4. Data Preprocessing </b>\n",
    "    - 4.1 Encoding categorical variables\n",
    "    - 4.2 Normalization\n",
    "    - 4.3 Split Training and testing\n",
    "    \n",
    "    \n",
    "    \n",
    "- <b>5. Models, Hyperparameter Tuning and Cross Validation</b>\n",
    "    - 5.1 Logistic Regression \n",
    "    - 5.2 Naive Bayes \n",
    "    - 5.3 K-Nearest Neighbor\n",
    "    - 5.4 Decision Tree\n",
    "    - 5.5 Random Forest\n",
    "    - 5.5 Support Vector Machine\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have already observed the data and the features. So we will skip the part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Cleaning\n",
    "\n",
    "- 2.1 Outliers\n",
    "- 2.2 Filling null values\n",
    "- 2.3 Check for data imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Oultiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no any possibility of having Outliers. All the values are squeezed between -1 to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Checking for NaN/null values and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Duplicates Train: {} \\n\".format(sum(df_train.duplicated())))\n",
    "print(\"Total Duplicates in Test: {} \\n\".format(sum(df_test.duplicated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Null values in Train: {}\\n\".format(df_train.isnull().values.sum()))\n",
    "print(\"Total Null values in Test: {} \\n\".format(df_test.isnull().values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check for imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.title('Subjects')\n",
    "sns.countplot(x = 'subject', data = df_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "plt.title(\"Subject with Each Activity\")\n",
    "sns.countplot(hue = 'Activity', x='subject',data = df_train);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.countplot(x = 'Activity', data = df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see, each subjects has almost equal or less amount of data. There is no any huge amount of gap between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Correcting some feature names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, some () 'bracket' between the feature's name. We will remove all these brackets quickly. So it's easier for us to type correctly later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns\n",
    "\n",
    "## Removing ()\n",
    "\n",
    "columns = columns.str.replace('[()]','')\n",
    "columns = columns.str.replace('[-]','')\n",
    "columns = columns.str.replace('[,]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "\n",
    "#### Static and Dynamic Activites\n",
    "\n",
    "- Static activities are (sit, stand, lie and down) thus there is no any motion of an object. \n",
    "- Dynamic activities (Walking, WalkingUpStairs, WalkingDownStairs) motion info will be significant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Stationary and Moving activities are completely different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(\"Set1\", desat=0.80)\n",
    "facetgrid = sns.FacetGrid(df_train, hue='Activity', size=6,aspect=2)\n",
    "facetgrid.map(sns.distplot,'tBodyAccMagmean', hist=False)\\\n",
    "    .add_legend()\n",
    "plt.annotate(\"Stationary Activities\", xy=(-0.956,17), xytext=(-0.9, 23), size=20,\\\n",
    "            va='center', ha='left',\\\n",
    "            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\n",
    "\n",
    "plt.annotate(\"Moving Activities\", xy=(0,3), xytext=(0.2, 9), size=20,\\\n",
    "            va='center', ha='left',\\\n",
    "            arrowprops=dict(arrowstyle=\"simple\",connectionstyle=\"arc3,rad=0.1\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Static Activities (closer view)\")\n",
    "sns.distplot(df_train[df_train[\"Activity\"]==\"SITTING\"]['tBodyAccMagmean'], hist = False, label = 'Sitting');\n",
    "sns.distplot(df_train[df_train[\"Activity\"]==\"STANDING\"]['tBodyAccMagmean'], hist = False, label = 'Standing');\n",
    "sns.distplot(df_train[df_train[\"Activity\"]==\"LAYING\"]['tBodyAccMagmean'], hist = False, label = 'Laying');\n",
    "plt.axis([-1.02, -0.5, 0, 35])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Dynamic Activities (closer view)\")\n",
    "sns.distplot(df_train[df_train[\"Activity\"]==\"WALKING\"][\"tBodyAccMagmean\"], hist = False, label =\"Sitting\");\n",
    "sns.distplot(df_train[df_train[\"Activity\"]==\"WALKING_UPSTAIRS\"]['tBodyAccMagmean'], hist = False, label = 'Laying');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also, use box plot to visulaize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sns.boxplot(x = 'Activity', y ='tBodyAccMagmean', data = df_train, showfliers = False);\n",
    "plt.ylabel('Body Acceleration Magnitude mean')\n",
    "plt.title('Boxplot of tBodyAccMagmean column across various activities')\n",
    "plt.axhline(y =- 0.7, xmin = 0.1, xmax = 0.9, dashes = (3,3))\n",
    "plt.axhline(y = 0.020, xmin = 0.4, dashes = (3,3))\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using boxplot agian, we can come with conditions to seperate static activities from dynamic activities.\n",
    "\n",
    "`` if(tBodyAccMagmean <= -0.8):\n",
    "      Activity = \"static\"\n",
    "  if(tBodyAccMagmean >= -0.6):\n",
    "      Activity = \"dynamic\"\n",
    " ``\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can easily seperate WALKING_DOWNSTAIRS activity from others using boxplot.\n",
    "\n",
    "`` \n",
    "if (tBodyAccMagmean > 0.02):\n",
    "    Activity = \"WALKING_DOWNSTARIS\"\n",
    "else:\n",
    "    Activity = \"others\"\n",
    "``\n",
    "\n",
    "But still 25% of WALKING_DOWNSTAIRS observations are below 0.02 which are misclassified as others so this condition makes an error of 25% in classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Analysing Angle between X-axis and gravityMean feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sns.boxplot(x = 'Activity', y = 'angleXgravityMean', data = df_train, showfliers = False)\n",
    "plt.axhline(y = 0.08, xmin = 0.1 , xmax = 0.9, dashes = (3,3))\n",
    "plt.ylabel(\"Angle between X-axis and gravityMean\")\n",
    "plt.title(\"Box plot of angleXgravityMean column across various activities\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Observation: </b>\n",
    "- If angleXgravityMean > 0.01 then Activity is <b> Laying </b>\n",
    "- We can classify all datapoints belonging to Laying activity with just a single if else statement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Analysing Angle between Y-axis and gravityMean feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sns.boxplot(x = 'Activity', y = 'angleYgravityMean', data = df_train, showfliers = False)\n",
    "plt.ylabel(\"Angle between Y-axis and gravityMean\")\n",
    "plt.title(\"Box plot of angleYgravitymean column across various activities\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.axhline(y = -0.35, xmin = 0.01, dashes = (3,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Visualizing data using t-SNE\n",
    "\n",
    "Using t-SNE data can be visualized from a extermely high dimensional space to a low dimensional space and still it retains lots of actual information. Given training data has 561 unique featuers, using t-SNE let's visualze it to a 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_tsne = df_train.drop(['subject','Activity'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "tsne = TSNE(random_state = 42, n_components = 2, verbose = 1, perplexity = 50, n_iter = 1000).fit_transform(X_for_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(x = tsne[:,0], y = tsne[:,1], hue = df_train[\"Activity\"], palette = \"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observations:</b>\n",
    "- Laying is totally different position\n",
    "- Walking, Walking_downstaris, Walking_upstairs are some kind of similar so they are clustered together\n",
    "- And, Standing and Sitting are also some kind of same position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 4.1 Splitting training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.Activity\n",
    "X_train = df_train.drop(['subject','Activity'], axis = 1)\n",
    "y_test = df_test.Activity\n",
    "X_test = df_test.drop(['subject','Activity'], axis = 1)\n",
    "print('Training data size:', X_train.shape)\n",
    "print('Test data size:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = pd.DataFrame(columns = (\"Model\",\"Score\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models, HyperparamterTuning and Cross Validations\n",
    "- Logistic Regression \n",
    "- Linear SVM\n",
    "- Kernel SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Logistic regression model with Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':np.arange(10,61,10),'penalty':['l2','l1']}\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier_rs = RandomizedSearchCV(lr_classifier, param_distributions = parameters, cv = 5, random_state = 42)\n",
    "lr_classifier_rs.fit(X_train, y_train)\n",
    "y_pred = lr_classifier_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "print(\"Accuracy using Logisitc Regression:\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model_score.append(pd.DataFrame({'Model':[\"LogisticRegression\"],'Score':[lr_accuracy]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, lables):\n",
    "    fig, ax = plt.subplots(figsize = (12,8))\n",
    "    im = ax.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax = ax)\n",
    "    ax.set(xticks = np.arange(cm.shape[1]))\n",
    "    yticks = np.arange(cm.shape[0])\n",
    "    ylabel = 'True label'\n",
    "    xlabel = 'Predicted label'\n",
    "    plt.xticks(rotation = 90)\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, int(cm[i,j]), ha = \"center\", va = \"center\", color = \"white\" if cm[i,j]> thresh else \"black\")\n",
    "            fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plot_confusion_matrix(cm, np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get best random search attributes\n",
    "\n",
    "def get_best_randomsearch_results(model):\n",
    "    print(\"Best estimator:\", model.best_estimator_)\n",
    "    print(\"Best set of parameters:\", model.best_params_)\n",
    "    print(\"Best score:\", model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting best random search attributes\n",
    "\n",
    "get_best_randomsearch_results(lr_classifier_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Linear SVM model with Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C': np.arange(1,12,2)}\n",
    "lr_svm = LinearSVC(tol = 0.00005)\n",
    "lr_svm_rs = RandomizedSearchCV(lr_svm, param_distributions = parameters, random_state = 42)\n",
    "lr_svm_rs.fit(X_train, y_train)\n",
    "y_pred = lr_svm_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_svm_accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "print(\"Accuracy using Linear SVM:\", lr_svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model_score.append(pd.DataFrame({'Model':[\"LinearSVM\"],'Score':[lr_svm_accuracy]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plot_confusion_matrix(cm, np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting best random search attributes\n",
    "get_best_randomsearch_results(lr_svm_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Kernel SVM model with Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(2,22, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'C':[2,4,8,16], 'gamma':[0.125, 0.250, 0.5, 1]}\n",
    "kernel_svm = SVC(kernel = 'rbf')\n",
    "kernel_svm_rs = RandomizedSearchCV(kernel_svm, param_distributions = parameters, random_state = 42)\n",
    "kernel_svm_rs.fit(X_train, y_train)\n",
    "y_pred = kernel_svm_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_svm_accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "print(\"Accuracy using Kernel SVM:\", kernel_svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model_score.append(pd.DataFrame({'Model':[\"KernelSVM\"],'Score':[kernel_svm_accuracy]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plot_confusion_matrix(cm, np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting best random search attributes\n",
    "\n",
    "get_best_randomsearch_results(kernel_svm_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Decision tree model with Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':np.arange(2,10,2)}\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier_rs = RandomizedSearchCV(dt_classifier,param_distributions=parameters,random_state = 42)\n",
    "dt_classifier_rs.fit(X_train, y_train)\n",
    "y_pred = dt_classifier_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_accuracy = accuracy_score(y_true = y_test, y_pred = y_pred)\n",
    "print(\"Accuracy using Decision tree:\", dt_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model_score.append(pd.DataFrame({'Model':[\"DecisionTrees\"],'Score':[dt_accuracy]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plot_confusion_matrix(cm, np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting best estimators\n",
    "\n",
    "get_best_randomsearch_results(dt_classifier_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Random Forest model using Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': np.arange(20,101,10), 'max_depth':np.arange(2,16,2)}\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier_rs = RandomizedSearchCV(rf_classifier, param_distributions=params,random_state = 42)\n",
    "rf_classifier_rs.fit(X_train, y_train)\n",
    "y_pred = rf_classifier_rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy using Random Forest:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model_score.append(pd.DataFrame({'Model':[\"RandomForest\"],'Score':[rf_accuracy]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plot_confusion_matrix(cm, np.unique(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
